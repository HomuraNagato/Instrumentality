{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter data collection\n",
    "\n",
    "#### References\n",
    "\n",
    "searchtweets API reference: https://twitterdev.github.io/search-tweets-python/  \n",
    "Twitter API reference: https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search.html  \n",
    "Twitter tweet object and dictionary: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n",
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials, collect_results\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# plotting and visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "premium_search_args_30day = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_30day\",\n",
    "                                          env_overwrite=False)\n",
    "premium_search_args_fullarchive = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_fullarchive\",\n",
    "                                          env_overwrite=False)\n",
    "\n",
    "# for na-young-joo\n",
    "# premium_search_args_30day = load_credentials(\"~/Documents/Research/.twitter_keys.yaml\",\n",
    "#                                           yaml_key=\"search_tweets_premium_30day\",\n",
    "#                                           env_overwrite=False)\n",
    "# premium_search_args_fullarchive = load_credentials(\"~/Documents/Research/.twitter_keys.yaml\",\n",
    "#                                           yaml_key=\"search_tweets_premium_fullarchive\",\n",
    "#                                           env_overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_collect(start, end, frequency):\n",
    "    '''\n",
    "    will return an array starting at midnight of desired date to last frequency hour of end date\n",
    "    start = start date\n",
    "    end = end date\n",
    "    frequency = number of hours to step by per day. For example frequency = 12, will collect twice: at midnight and noon\n",
    "    '''\n",
    "    # add one day for right_side border case\n",
    "    # pd.date_range only allows dates, use rounding dates and closed='right' to get desired dates\n",
    "    #print(start, end)\n",
    "    start = datetime.datetime.strptime(start, '%Y-%m-%d') - datetime.timedelta(days=0, hours=int(frequency))\n",
    "    end = datetime.datetime.strptime(end, '%Y-%m-%d') + datetime.timedelta(days=1, hours=0)\n",
    "    #print(start, end)\n",
    "    dates = pd.date_range(start=start, end=end, freq=frequency+'H', closed='left')\n",
    "    formatted_dates = [ datetime.datetime.strftime(t, '%Y%m%d%H%M') for t in dates ]\n",
    "    #print(formatted_dates)\n",
    "    return formatted_dates\n",
    "\n",
    "def collect_tweets(from_date, to_date, max_results):\n",
    "    # maxResults is capped at 100 for sandbox account, even though there should be a next function to get more, it \n",
    "    # appears max_results=500 is accepted without any extra work\n",
    "    # date format: YYYY-mm-DD HH:MM\n",
    "    # from_date is inclusive. to_date is non-inclusive. Appears to start at from_date and start collecting tweets working\n",
    "    # backwards to to_date\n",
    "    bitcoin_rule = gen_rule_payload(\"bitcoin\", results_per_call=100, from_date=from_date, to_date=to_date) \n",
    "    print(bitcoin_rule)\n",
    "    collected_tweets = collect_results(bitcoin_rule, max_results=max_results, result_stream_args=premium_search_args)\n",
    "    return collected_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intra-day hour interval is set to 24 Edit the code if desired to change this\n",
      "The number of tweets per interval is set to 100 Edit the code if desired to change this\n",
      "please input two dates in the format below to collect dates\n",
      "\t 2018-10-11 2018-10-15 \n",
      "\n",
      "\t2019-02-16 2019-02-18\n",
      "\n",
      "will use 30-day dev environment\n",
      "\n",
      "twitter recognized dates will be collected on the closed iterval from 2019-02-16 to 2019-02-18 spaced in 24 hour intervals\n"
     ]
    }
   ],
   "source": [
    "example_start_date = '2018-10-11'\n",
    "example_end_date = '2018-10-15'\n",
    "interval = 12\n",
    "results_per_call=100\n",
    "max_results = 100\n",
    "\n",
    "print(\"The intra-day hour interval is set to\", interval, \"Edit the code if desired to change this\")\n",
    "print(\"The number of tweets per interval is set to\", max_results, \"Edit the code if desired to change this\")\n",
    "print(\"please input two dates in the format below to collect dates\\n\\t\", example_start_date, example_end_date, \"\\n\")\n",
    "user_dates = input(\"\\t\")\n",
    "print()\n",
    "start_date, end_date = user_dates.split(' ')\n",
    "test_dates = days_to_collect(start_date, end_date, str(interval))\n",
    "\n",
    "if (datetime.datetime.fromtimestamp(time.time()) - datetime.datetime.strptime(start_date, '%Y-%m-%d')).days < 30:\n",
    "    premium_search_args = premium_search_args_30day\n",
    "    print(\"will use 30-day dev environment\")\n",
    "else:\n",
    "    premium_search_args = premium_search_args_fullarchive\n",
    "    print(\"will use full-archive dev environment\")\n",
    "    \n",
    "print(\"\\ntwitter recognized dates will be collected on the closed iterval from\", start_date, \"to\", end_date, \"spaced in\", str(interval), \"hour intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201902160000\", \"fromDate\": \"201902150000\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201902170000\", \"fromDate\": \"201902160000\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201902180000\", \"fromDate\": \"201902170000\"}\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in range(0,len(test_dates[:-1])):\n",
    "    tweets = np.append(tweets, collect_tweets(test_dates[i], test_dates[i+1], max_results=max_results))\n",
    "    \n",
    "    # Requests are limited to 30 per minute for sandbox, 60 for subscriptions \n",
    "    # Requests are limited to 10 per second\n",
    "    num_calls = (i + 1) * max_results//results_per_call\n",
    "    if num_calls % 10 == 0 and num_calls % 20 != 0:\n",
    "        print(\"waiting 2 seconds\")\n",
    "        time.sleep(2)\n",
    "    if num_calls % 20 == 0:\n",
    "        print(\"waiting 60 seconds\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-727a23f4a713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "tweets[-1]\n",
    "tweets.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To dataframe and csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_df(tweets):\n",
    "    # create a pandas df from tweets\n",
    "    S2 = pd.DataFrame(columns=['tweets', 'date', 'user_name', 'user_screen_name', 'user_followers', \n",
    "                           'user_friends', 'user_verified', 'user_language', 'retweet_count', 'favorite_count'])\n",
    "\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        S2.loc[i] = [tweet['text'], \n",
    "                     tweet['created_at'], \n",
    "                     tweet['user']['name'], \n",
    "                     tweet['user']['screen_name'], \n",
    "                     tweet['user']['followers_count'], \n",
    "                     tweet['user']['friends_count'], \n",
    "                     tweet['user']['verified'], \n",
    "                     tweet['user']['lang'], \n",
    "                     tweet['retweet_count'], \n",
    "                     tweet['favorite_count']] \n",
    "    return S2\n",
    "\n",
    "S2 = to_df(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_language</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>RT @coindesk: A new proposed exchange-traded f...</td>\n",
       "      <td>Sun Feb 17 23:59:49 +0000 2019</td>\n",
       "      <td>Derek Sears</td>\n",
       "      <td>dereksears</td>\n",
       "      <td>226</td>\n",
       "      <td>1707</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2015 Lambo Huracan costs $175k or 46.84  BTC t...</td>\n",
       "      <td>Sun Feb 17 23:59:50 +0000 2019</td>\n",
       "      <td>LamboBTC</td>\n",
       "      <td>LamboBTC</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>#BeLLCoin #BeLLPlatform #BeLLDEX #blockchain #...</td>\n",
       "      <td>Sun Feb 17 23:59:52 +0000 2019</td>\n",
       "      <td>imam</td>\n",
       "      <td>imam79726953</td>\n",
       "      <td>2610</td>\n",
       "      <td>3352</td>\n",
       "      <td>False</td>\n",
       "      <td>id</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>RT @BitcoinEdu: Found this at waves coffee in ...</td>\n",
       "      <td>Sun Feb 17 23:59:56 +0000 2019</td>\n",
       "      <td>World Trade Stocks</td>\n",
       "      <td>Wall_Streets</td>\n",
       "      <td>2494</td>\n",
       "      <td>1536</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>RT @TheStalwart: Bitcoin is dead https://t.co/...</td>\n",
       "      <td>Sun Feb 17 23:59:57 +0000 2019</td>\n",
       "      <td>Ibrahim Ali Mansour</td>\n",
       "      <td>imansourx</td>\n",
       "      <td>57</td>\n",
       "      <td>135</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweets  \\\n",
       "295  RT @coindesk: A new proposed exchange-traded f...   \n",
       "296  2015 Lambo Huracan costs $175k or 46.84  BTC t...   \n",
       "297  #BeLLCoin #BeLLPlatform #BeLLDEX #blockchain #...   \n",
       "298  RT @BitcoinEdu: Found this at waves coffee in ...   \n",
       "299  RT @TheStalwart: Bitcoin is dead https://t.co/...   \n",
       "\n",
       "                               date            user_name user_screen_name  \\\n",
       "295  Sun Feb 17 23:59:49 +0000 2019          Derek Sears       dereksears   \n",
       "296  Sun Feb 17 23:59:50 +0000 2019             LamboBTC         LamboBTC   \n",
       "297  Sun Feb 17 23:59:52 +0000 2019                 imam     imam79726953   \n",
       "298  Sun Feb 17 23:59:56 +0000 2019   World Trade Stocks     Wall_Streets   \n",
       "299  Sun Feb 17 23:59:57 +0000 2019  Ibrahim Ali Mansour        imansourx   \n",
       "\n",
       "    user_followers user_friends user_verified user_language retweet_count  \\\n",
       "295            226         1707         False            en             0   \n",
       "296             30           15         False            en             0   \n",
       "297           2610         3352         False            id             0   \n",
       "298           2494         1536         False            en             0   \n",
       "299             57          135         False            en             0   \n",
       "\n",
       "    favorite_count  \n",
       "295              0  \n",
       "296              0  \n",
       "297              1  \n",
       "298              0  \n",
       "299              0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved files complete_tweets/tweets_2019-02-16_2019-02-18_Tweets.csv and complete_tweets/tweets_2019-02-16_2019-02-18_Metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# save file to csv\n",
    "S2_tweets = S2.loc[:,['tweets']]\n",
    "S2_meta = S2.drop(['tweets'], axis=1)\n",
    "\n",
    "filename = 'complete_tweets/tweets_' + start_date + '_' + end_date\n",
    "S2_tweets.to_csv(filename + '_Tweets.csv', index=False)\n",
    "S2_meta.to_csv(filename + '_Metadata.csv', index=False)\n",
    "print('saved files', filename + '_Tweets.csv', 'and', filename + '_Metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/m2/anaconda3/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "# sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
