{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoin sentiment analysis using Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "searchtweets API reference: https://twitterdev.github.io/search-tweets-python/  \n",
    "Twitter API reference: https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search.html  \n",
    "Twitter tweet object and dictionary: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object  \n",
    "\n",
    "`~/.twitter_keys` contains endpoint, consumer_key, and consumer_secret  \n",
    "Change `yaml_key` to get data for the last 30 days (250 queries / month) or since Twitters inception - 2006 (50 queries / month)  \n",
    "`yaml_key = \"search_tweets_premium_30day\"`  \n",
    "`yaml_key = \"search_tweets_premium_archive\"`:  \n",
    "\n",
    "\n",
    "Each stream increments query  \n",
    "For example, if `results_per_call` is 100 and `max_results` is 1000, that is 10 queries  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter metadata\n",
    "\n",
    " - Text\n",
    " - Date\n",
    " - User\n",
    " - Place.full_name, Place.country\n",
    " - Retweet_count\n",
    " - Favorite_count (likes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials, collect_results\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tweepy\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# plotting and visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "premium_search_args = load_credentials(\"~/Documents/Research/Twitter/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_archive\",\n",
    "                                          env_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bearer_token': 'AAAAAAAAAAAAAAAAAAAAAMkh8wAAAAAAKjpbbf0g3sMvc5EofBU%2BTcPuado%3DGaRFNKdtFOjT3zkaTlyzkdNn7IGPx8vrAmwRHBNvSw8VFKEt87', 'endpoint': 'https://api.twitter.com/1.1/tweets/search/fullarchive/development.json', 'extra_headers_dict': None}\n"
     ]
    }
   ],
   "source": [
    "print(premium_search_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_collect(start, end, frequency):\n",
    "    '''\n",
    "    will return an array starting at midnight of desired date to last frequency hour of end date\n",
    "    start = start date\n",
    "    end = end date\n",
    "    frequency = number of hours to step by per day. For example frequency = 12, will collect twice: at midnight and noon\n",
    "    '''\n",
    "    # add one day for right_side border case\n",
    "    # pd.date_range only allows dates, use rounding dates and closed='right' to get desired dates\n",
    "    #print(start, end)\n",
    "    start = datetime.datetime.strptime(start, '%Y-%m-%d') - datetime.timedelta(days=0, hours=int(frequency)) \n",
    "    end = datetime.datetime.strptime(end, '%Y-%m-%d') + datetime.timedelta(days=1, hours=0)\n",
    "    #print(start, end)\n",
    "    dates = pd.date_range(start=start, end=end, freq=frequency+'H', closed='left')\n",
    "    formatted_dates = [ datetime.datetime.strftime(t, '%Y%m%d%H%M') for t in dates ]\n",
    "    #print(formatted_dates)\n",
    "    return formatted_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twitter recognized dates will be collected on the closed iterval from 201809100000 to 201809141200\n"
     ]
    }
   ],
   "source": [
    "test_dates = days_to_collect('2018-09-10', '2018-09-14', '12')\n",
    "print(\"twitter recognized dates will be collected on the closed iterval from\", test_dates[1], \"to\", test_dates[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 201809091200\n",
      "1 201809100000\n",
      "2 201809101200\n",
      "3 201809110000\n",
      "4 201809111200\n",
      "5 201809120000\n",
      "6 201809121200\n",
      "7 201809130000\n",
      "8 201809131200\n",
      "9 201809140000\n",
      "10 201809141200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(i, d) for i, d in enumerate(test_dates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tweets(from_date, to_date):\n",
    "    # maxResults is capped at 100 for sandbox account, even though there should be a next function to get more, it \n",
    "    # appears max_results=500 is accepted without any extra work\n",
    "    # date format: YYYY-mm-DD HH:MM\n",
    "    # from_date is inclusive. to_date is non-inclusive. Appears to start at from_date and start collecting tweets working\n",
    "    # backwards to to_date\n",
    "    bitcoin_rule = gen_rule_payload(\"bitcoin\", results_per_call=100, from_date=from_date, to_date=to_date) \n",
    "    print(bitcoin_rule)\n",
    "    collected_tweets = collect_results(bitcoin_rule, max_results=500, result_stream_args=premium_search_args)\n",
    "    return collected_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809100000\", \"fromDate\": \"201809091200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809101200\", \"fromDate\": \"201809100000\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809110000\", \"fromDate\": \"201809101200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809111200\", \"fromDate\": \"201809110000\"}\n",
      "waiting 60 seconds\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809120000\", \"fromDate\": \"201809111200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809121200\", \"fromDate\": \"201809120000\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809130000\", \"fromDate\": \"201809121200\"}\n",
      "waiting 60 seconds\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809131200\", \"fromDate\": \"201809130000\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809140000\", \"fromDate\": \"201809131200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201809141200\", \"fromDate\": \"201809140000\"}\n",
      "waiting 60 seconds\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in range(0,len(test_dates[:-1])):\n",
    "    tweets = np.append(tweets, collect_tweets(test_dates[i], test_dates[i+1]))\n",
    "    if i % 3 == 0 and i != 0:\n",
    "        print(\"waiting 60 seconds\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 Sun Sep 09 23:59:56 +0000 2018 Fri Sep 14 11:51:29 +0000 2018\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets), tweets[0]['created_at'], tweets[-1]['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Mon Sep 10 23:59:56 +0000 2018',\n",
       " 'id': 1039302485666488324,\n",
       " 'id_str': '1039302485666488324',\n",
       " 'text': 'https://t.co/BaZSqu1XgK\\n #such as #Cryptocurrency #Airdrop #Bounty #Bitcoin',\n",
       " 'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Lite</a>',\n",
       " 'truncated': False,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 1037952138846986240,\n",
       "  'id_str': '1037952138846986240',\n",
       "  'name': 'Mwidodo',\n",
       "  'screen_name': 'Mwidodo50109960',\n",
       "  'location': None,\n",
       "  'url': None,\n",
       "  'description': None,\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 0,\n",
       "  'friends_count': 20,\n",
       "  'listed_count': 0,\n",
       "  'favourites_count': 0,\n",
       "  'statuses_count': 8,\n",
       "  'created_at': 'Fri Sep 07 06:34:08 +0000 2018',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'lang': 'en',\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': 'F5F8FA',\n",
       "  'profile_background_image_url': '',\n",
       "  'profile_background_image_url_https': '',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '1DA1F2',\n",
       "  'profile_sidebar_border_color': 'C0DEED',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'profile_image_url': 'http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png',\n",
       "  'profile_image_url_https': 'https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png',\n",
       "  'default_profile': True,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [{'text': 'such', 'indices': [25, 30]},\n",
       "   {'text': 'Cryptocurrency', 'indices': [34, 49]},\n",
       "   {'text': 'Airdrop', 'indices': [50, 58]},\n",
       "   {'text': 'Bounty', 'indices': [59, 66]},\n",
       "   {'text': 'Bitcoin', 'indices': [67, 75]}],\n",
       "  'urls': [{'url': 'https://t.co/BaZSqu1XgK',\n",
       "    'expanded_url': 'https://bounty.trakx.io/6217/4863495',\n",
       "    'display_url': 'bounty.trakx.io/6217/4863495',\n",
       "    'indices': [0, 23]}],\n",
       "  'user_mentions': [],\n",
       "  'symbols': []},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'und',\n",
       " 'matching_rules': [{'tag': None}]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### counts and limitations\n",
    "\n",
    "A trial to collect all tweets containing the string 'bitcoin' from the current date until a max number of tweets=1000 reached was 15 minutes. If the max number of tweets is increased, we will eventually go back in time to 30 days. To capture more data beyond this time, Full archive will need to be used. However, with only 50 requests per month, very finely specified dates to remain under 50 requests will need to be identified. I.E. once a month we can collect 25,000 tweets for the last 30 days or 5,000 for some time period earlier than that. For full archive to collect as many as montly, requires subscription of $225/month. Thousands to get over a million tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pandas df from tweets\n",
    "S2 = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['Tweets'])\n",
    "S2['Date'] = [tweet['created_at'] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @FiveMining: FSN token public sale is openi...</td>\n",
       "      <td>Sun Sep 09 23:59:56 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How to Teach Kids About Cryptocurrency and Blo...</td>\n",
       "      <td>Sun Sep 09 23:59:56 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @FiveMining: The public sale is open now! D...</td>\n",
       "      <td>Sun Sep 09 23:59:52 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @grinMW: The Crypto-Dungeon of #Mimblewimbl...</td>\n",
       "      <td>Sun Sep 09 23:59:49 +0000 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Interested in joining =&amp;gt; hit me or any of t...</td>\n",
       "      <td>Sun Sep 09 23:59:45 +0000 2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  RT @FiveMining: FSN token public sale is openi...   \n",
       "1  How to Teach Kids About Cryptocurrency and Blo...   \n",
       "2  RT @FiveMining: The public sale is open now! D...   \n",
       "3  RT @grinMW: The Crypto-Dungeon of #Mimblewimbl...   \n",
       "4  Interested in joining =&gt; hit me or any of t...   \n",
       "\n",
       "                             Date  \n",
       "0  Sun Sep 09 23:59:56 +0000 2018  \n",
       "1  Sun Sep 09 23:59:56 +0000 2018  \n",
       "2  Sun Sep 09 23:59:52 +0000 2018  \n",
       "3  Sun Sep 09 23:59:49 +0000 2018  \n",
       "4  Sun Sep 09 23:59:45 +0000 2018  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analize_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    \n",
    "    textblob already has a trained analyser to work \n",
    "    with different machine learning models on \n",
    "    natural language processing.\n",
    "    \n",
    "    Might want to train our own model\n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "\n",
    "def sentiment_analysis(S2):\n",
    "    # We create a column with the result of the analysis:\n",
    "    S2['SA'] = np.array([ analize_sentiment(tweet) for tweet in S2['Tweets'] ])\n",
    "    \n",
    "    # We construct lists with classified tweets:\n",
    "    pos_tweets = [ tweet for index, tweet in enumerate(S2['Tweets']) if S2['SA'][index] > 0]\n",
    "    neu_tweets = [ tweet for index, tweet in enumerate(S2['Tweets']) if S2['SA'][index] == 0]\n",
    "    neg_tweets = [ tweet for index, tweet in enumerate(S2['Tweets']) if S2['SA'][index] < 0]\n",
    "\n",
    "    # We print percentages:\n",
    "    print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(S2['Tweets'])))\n",
    "    print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(S2['Tweets'])))\n",
    "    print(\"Percentage de negative tweets: {}%\".format(len(neg_tweets)*100/len(S2['Tweets'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive tweets: 31.24%\n",
      "Percentage of neutral tweets: 56.8%\n",
      "Percentage de negative tweets: 11.96%\n"
     ]
    }
   ],
   "source": [
    "sentiment_analysis(S2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2['Tweets'].to_csv('tweets_2018-09-10_2018-09-14_Tweets.csv', index=False)\n",
    "S2['Date'].to_csv('tweets_2018-09-10_2018-09-14_Date.csv', index=False)\n",
    "S2.to_csv('tweets_2018-09-10_2018-09-14_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @CryptoInvest18: Best coin still under $1? ...</td>\n",
       "      <td>Sun Sep 30 23:59:54 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @kubitx: We are TRULY GLOBAL EXCHANGE... Aw...</td>\n",
       "      <td>Sun Sep 30 23:59:50 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TrezarCoin: We are proud to release Trezar...</td>\n",
       "      <td>Sun Sep 30 23:59:43 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @APompliano: REMINDER: A single bank locati...</td>\n",
       "      <td>Sun Sep 30 23:59:42 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The first ever #crypto bank opening in October...</td>\n",
       "      <td>Sun Sep 30 23:59:42 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  RT @CryptoInvest18: Best coin still under $1? ...   \n",
       "1  RT @kubitx: We are TRULY GLOBAL EXCHANGE... Aw...   \n",
       "2  RT @TrezarCoin: We are proud to release Trezar...   \n",
       "3  RT @APompliano: REMINDER: A single bank locati...   \n",
       "4  The first ever #crypto bank opening in October...   \n",
       "\n",
       "                             Date  SA  \n",
       "0  Sun Sep 30 23:59:54 +0000 2018   1  \n",
       "1  Sun Sep 30 23:59:50 +0000 2018   1  \n",
       "2  Sun Sep 30 23:59:43 +0000 2018   1  \n",
       "3  Sun Sep 30 23:59:42 +0000 2018   1  \n",
       "4  Sun Sep 30 23:59:42 +0000 2018   1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to rate limitations, not all data was able to be gathered at once and resulted in gaps in data. Running through the dates and re-collecting the data allowed for a continuous data collection from September 01-15\n",
    "\n",
    "Lowering the waiting period to occur once every 3 iterations rather than once every 10 allowed it to all run in one go~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sep 01-00:00\n",
    "S3_Date_0901A = pd.read_csv('tweets_2018-09-01-00_Date.csv', names=['Date'])\n",
    "S3_Tweets_0901A = pd.read_csv('tweets_2018-09-01-00_Tweets.csv', names=['Tweets'])\n",
    "# Sep 01-03\n",
    "S3_Date_090103 = pd.read_csv('tweets_2018-09-01_2018-09-03_Date.csv', names=['Date'])\n",
    "S3_Tweets_090103 = pd.read_csv('tweets_2018-09-01_2018-09-03_Tweets.csv', names=['Tweets'])\n",
    "# Sep 03-21:00\n",
    "S3_Date_0903A = pd.read_csv('tweets_2018-09-03-21_Date.csv', names=['Date'])\n",
    "S3_Tweets_0903A = pd.read_csv('tweets_2018-09-03-21_Tweets.csv', names=['Tweets'])\n",
    "# Sep 03-05\n",
    "S3_Date_090305 = pd.read_csv('tweets_2018-09-03_2018-09-05_Date.csv', names=['Date'])\n",
    "S3_Tweets_090305 = pd.read_csv('tweets_2018-09-03_2018-09-05_Tweets.csv', names=['Tweets'])\n",
    "# Sep 15-21:00\n",
    "S3_Date_0915A = pd.read_csv('tweets_2018-09-15-21_Date.csv', names=['Date'])\n",
    "S3_Tweets_0915A = pd.read_csv('tweets_2018-09-15-21_Tweets.csv', names=['Tweets'])\n",
    "# Sep 06-15\n",
    "S3_Date_090615 = pd.read_csv('tweets_2018-09-06_2018-09-15_Date.csv', names=['Date'])\n",
    "S3_Tweets_090615 = pd.read_csv('tweets_2018-09-06_2018-09-15_Tweets.csv', names=['Tweets'])\n",
    "\n",
    "S3_A = pd.concat([S3_Tweets_0901A, S3_Date_0901A], axis=1)\n",
    "S3_B = pd.concat([S3_Tweets_090103, S3_Date_090103], axis=1)\n",
    "S3_C = pd.concat([S3_Tweets_0903A, S3_Date_0903A], axis=1)\n",
    "S3_D = pd.concat([S3_Tweets_090305, S3_Date_090305], axis=1)\n",
    "S3_E = pd.concat([S3_Tweets_0915A, S3_Date_0915A], axis=1)\n",
    "S3_F = pd.concat([S3_Tweets_090615, S3_Date_090615], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Tweets  \\\n",
      "0  Haha @Eminem dropped that new album and name d...   \n",
      "1  RT @coingecko: Have you tried comparing coins ...   \n",
      "2  RT @cryptocomicon: Chris DeRose spends an 86 m...   \n",
      "3  RT @santisiri: un partido político que opera s...   \n",
      "4  RT @BitcoinDood: DNA: The Safest Way to Store ...   \n",
      "\n",
      "                             Date  \n",
      "0  Fri Aug 31 23:59:57 +0000 2018  \n",
      "1  Fri Aug 31 23:59:51 +0000 2018  \n",
      "2  Fri Aug 31 23:59:47 +0000 2018  \n",
      "3  Fri Aug 31 23:59:46 +0000 2018  \n",
      "4  Fri Aug 31 23:59:45 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  https://t.co/yLZluuYevy DECENTRALISED ENERGY P...   \n",
      "1  📉 Biggest Losers (1 hr) 📉\\nNoah Coin $NOAH -3....   \n",
      "2  Crypto News: Yahoo! World’s Sixth-Most Popular...   \n",
      "3  RT @coingecko: Have you tried comparing coins ...   \n",
      "4  Bitcoin Gets Awareness Boost From Mention On E...   \n",
      "\n",
      "                             Date  \n",
      "0  Sat Sep 01 02:59:59 +0000 2018  \n",
      "1  Sat Sep 01 02:59:58 +0000 2018  \n",
      "2  Sat Sep 01 02:59:54 +0000 2018  \n",
      "3  Sat Sep 01 02:59:54 +0000 2018  \n",
      "4  Sat Sep 01 02:59:53 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  RT @helexcorp: Our Public ICO is finished, tha...   \n",
      "1  RT @coinbundlecom: With Bitcoin down, which to...   \n",
      "2  Is the hype of blockchain starting to cool? An...   \n",
      "3  RT @patestevao: I'm finally starting a new inf...   \n",
      "4  #Bitcoin has a difficult task ahead - regardin...   \n",
      "\n",
      "                             Date  \n",
      "0  Mon Sep 03 20:59:59 +0000 2018  \n",
      "1  Mon Sep 03 20:59:58 +0000 2018  \n",
      "2  Mon Sep 03 20:59:52 +0000 2018  \n",
      "3  Mon Sep 03 20:59:52 +0000 2018  \n",
      "4  Mon Sep 03 20:59:43 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  RT @stakecube: 🎁HUGE BITCOIN W SPECTRUM GIVEAW...   \n",
      "1  @bitcoin_token @CoinDeal_ @Wolves @Stitcherako...   \n",
      "2  RT @Autobayio: A little weekend treat Autobaye...   \n",
      "3  RT @LovetronMajor: https://t.co/nNbdIo7uBU #mu...   \n",
      "4  @_M_o_z_a @_tm3k i think most of it is trollin...   \n",
      "\n",
      "                             Date  \n",
      "0  Mon Sep 03 23:59:57 +0000 2018  \n",
      "1  Mon Sep 03 23:59:54 +0000 2018  \n",
      "2  Mon Sep 03 23:59:51 +0000 2018  \n",
      "3  Mon Sep 03 23:59:48 +0000 2018  \n",
      "4  Mon Sep 03 23:59:47 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  Bitcoin Price Intraday Analysis: BTC/USD Break...   \n",
      "1  🔄 Prices update in $EUR (1 hour):\\n\\n$BTC - 57...   \n",
      "2  Alibaba Responsible for 10% of World's Blockch...   \n",
      "3  RT @Monarchtoken: Watch out for an amazing par...   \n",
      "4  RT @CNBCFastMoney: Goldman Sachs is reportedly...   \n",
      "\n",
      "                             Date  \n",
      "0  Wed Sep 05 23:59:58 +0000 2018  \n",
      "1  Wed Sep 05 23:59:57 +0000 2018  \n",
      "2  Wed Sep 05 23:59:56 +0000 2018  \n",
      "3  Wed Sep 05 23:59:46 +0000 2018  \n",
      "4  Wed Sep 05 23:59:45 +0000 2018   \n",
      "                                               Tweets  \\\n",
      "0  Buy/Sell Bitcoin changes with up to 100x Lever...   \n",
      "1  Free and Best Automatic Bitcoin - Altcoins - U...   \n",
      "2  RT @CryptoMoe81: $Bitcoin idea \"14,XX% Drop\" -...   \n",
      "3  Check out this awesome site! You can COPY pro ...   \n",
      "4  RT @APompliano: So many people are cheering ag...   \n",
      "\n",
      "                             Date  \n",
      "0  Thu Sep 06 02:59:59 +0000 2018  \n",
      "1  Thu Sep 06 02:59:57 +0000 2018  \n",
      "2  Thu Sep 06 02:59:56 +0000 2018  \n",
      "3  Thu Sep 06 02:59:54 +0000 2018  \n",
      "4  Thu Sep 06 02:59:53 +0000 2018  \n"
     ]
    }
   ],
   "source": [
    "print(S3_A.head(), '\\n', S3_B.head(), '\\n', S3_C.head(), '\\n', S3_D.head(), '\\n', S3_E.head(), '\\n', S3_F.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = pd.concat([S3_A, S3_B, S3_C, S3_D, S3_E, S3_F], axis=0)\n",
    "S3['Date'].to_csv('tweets_2018-08-01_2018-08-15_Date.csv', index=False)\n",
    "S3['Tweets'].to_csv('tweets_2018-08-01_2018-08-15_Tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @CryptoInvest18: Best coin still under $1? ...</td>\n",
       "      <td>Sun Sep 30 23:59:54 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @kubitx: We are TRULY GLOBAL EXCHANGE... Aw...</td>\n",
       "      <td>Sun Sep 30 23:59:50 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TrezarCoin: We are proud to release Trezar...</td>\n",
       "      <td>Sun Sep 30 23:59:43 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @APompliano: REMINDER: A single bank locati...</td>\n",
       "      <td>Sun Sep 30 23:59:42 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The first ever #crypto bank opening in October...</td>\n",
       "      <td>Sun Sep 30 23:59:42 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  RT @CryptoInvest18: Best coin still under $1? ...   \n",
       "1  RT @kubitx: We are TRULY GLOBAL EXCHANGE... Aw...   \n",
       "2  RT @TrezarCoin: We are proud to release Trezar...   \n",
       "3  RT @APompliano: REMINDER: A single bank locati...   \n",
       "4  The first ever #crypto bank opening in October...   \n",
       "\n",
       "                             Date  SA  \n",
       "0  Sun Sep 30 23:59:54 +0000 2018   1  \n",
       "1  Sun Sep 30 23:59:50 +0000 2018   1  \n",
       "2  Sun Sep 30 23:59:43 +0000 2018   1  \n",
       "3  Sun Sep 30 23:59:42 +0000 2018   1  \n",
       "4  Sun Sep 30 23:59:42 +0000 2018   1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Date</th>\n",
       "      <th>SA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>#Earn #BITCOIN  in differents ways!\\n* Spin - ...</td>\n",
       "      <td>Fri Oct 05 11:49:55 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>#XBlock #Blockchain #Crypto #ether #ethereum #...</td>\n",
       "      <td>Fri Oct 05 11:49:54 +0000 2018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>RT @adam3us: On the elemental supply chain HW ...</td>\n",
       "      <td>Fri Oct 05 11:49:52 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>RT @GRDO411: For clarity, $GRDO no longer has ...</td>\n",
       "      <td>Fri Oct 05 11:49:52 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Who's buying bitcoin? A lot of young, fairly a...</td>\n",
       "      <td>Fri Oct 05 11:49:51 +0000 2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweets  \\\n",
       "4995  #Earn #BITCOIN  in differents ways!\\n* Spin - ...   \n",
       "4996  #XBlock #Blockchain #Crypto #ether #ethereum #...   \n",
       "4997  RT @adam3us: On the elemental supply chain HW ...   \n",
       "4998  RT @GRDO411: For clarity, $GRDO no longer has ...   \n",
       "4999  Who's buying bitcoin? A lot of young, fairly a...   \n",
       "\n",
       "                                Date  SA  \n",
       "4995  Fri Oct 05 11:49:55 +0000 2018   0  \n",
       "4996  Fri Oct 05 11:49:54 +0000 2018   0  \n",
       "4997  Fri Oct 05 11:49:52 +0000 2018   1  \n",
       "4998  Fri Oct 05 11:49:52 +0000 2018   1  \n",
       "4999  Fri Oct 05 11:49:51 +0000 2018   1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary so far\n",
    "\n",
    "It's reasonable to assume that twitter data is more interesting when viewed as a larger picture than a collection centered around a pinpoint. To do this, subsamples of twitter data need to be gathered for a range of days. Tweets starting and ending on the dates listed below are gathered. The from_date is the listed day and the to_date is set to the next day. However rate limits will terminate early after 100 tweets have been gathered for that day, so typically only a couple minutes of tweets per day per every three hours. This method of collection 100 tweets per day is an efficient method to collect a fraction twitter data over a larger number of days. \n",
    "\n",
    "- 1944 2018-9-1 00:00\n",
    "- 2063 2018-9-15 21:00\n",
    " \n",
    "Sentiment analysis follows the preformulated TextBlob sentiment ML scoring algorithm. The data is then stored in a dataframe called S2 and written to individual csvs (due to texts containing commas as well, rather than fight it, just keep it separate) to paste back into a dataframe for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practicing working on branch\n"
     ]
    }
   ],
   "source": [
    "print(\"practicing working on branch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
