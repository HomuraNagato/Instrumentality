{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter data collection\n",
    "\n",
    "#### References\n",
    "\n",
    "searchtweets API reference: https://twitterdev.github.io/search-tweets-python/  \n",
    "Twitter API reference: https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search.html  \n",
    "Twitter tweet object and dictionary: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n",
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials, collect_results\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# plotting and visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "premium_search_args_30day = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_30day\",\n",
    "                                          env_overwrite=False)\n",
    "premium_search_args_fullarchive = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_fullarchive\",\n",
    "                                          env_overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_collect(start, end, frequency):\n",
    "    '''\n",
    "    will return an array starting at midnight of desired date to last frequency hour of end date\n",
    "    start = start date\n",
    "    end = end date\n",
    "    frequency = number of hours to step by per day. For example frequency = 12, will collect twice: at midnight and noon\n",
    "    '''\n",
    "    # add one day for right_side border case\n",
    "    # pd.date_range only allows dates, use rounding dates and closed='right' to get desired dates\n",
    "    #print(start, end)\n",
    "    start = datetime.datetime.strptime(start, '%Y-%m-%d') - datetime.timedelta(days=0, hours=int(frequency))\n",
    "    end = datetime.datetime.strptime(end, '%Y-%m-%d') + datetime.timedelta(days=1, hours=0)\n",
    "    #print(start, end)\n",
    "    dates = pd.date_range(start=start, end=end, freq=frequency+'H', closed='left')\n",
    "    formatted_dates = [ datetime.datetime.strftime(t, '%Y%m%d%H%M') for t in dates ]\n",
    "    #print(formatted_dates)\n",
    "    return formatted_dates\n",
    "\n",
    "def collect_tweets(from_date, to_date, max_results):\n",
    "    # maxResults is capped at 100 for sandbox account, even though there should be a next function to get more, it \n",
    "    # appears max_results=500 is accepted without any extra work\n",
    "    # date format: YYYY-mm-DD HH:MM\n",
    "    # from_date is inclusive. to_date is non-inclusive. Appears to start at from_date and start collecting tweets working\n",
    "    # backwards to to_date\n",
    "    bitcoin_rule = gen_rule_payload(\"bitcoin\", results_per_call=100, from_date=from_date, to_date=to_date) \n",
    "    print(bitcoin_rule)\n",
    "    collected_tweets = collect_results(bitcoin_rule, max_results=max_results, result_stream_args=premium_search_args)\n",
    "    return collected_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intra-day hour interval is set to 12 Edit the code if desired to change this\n",
      "The number of tweets per interval is set to 500 Edit the code if desired to change this\n",
      "please input two dates in the format below to collect dates\n",
      "\t 2018-10-11 2018-10-15 \n",
      "\n",
      "\t2018-10-01 2018-10-05\n",
      "\n",
      "will use full-archive dev environment\n",
      "\n",
      "twitter recognized dates will be collected on the closed iterval from 2018-10-01 to 2018-10-05 spaced in 12 hour intervals\n"
     ]
    }
   ],
   "source": [
    "example_start_date = '2018-10-11'\n",
    "example_end_date = '2018-10-15'\n",
    "interval = 12\n",
    "results_per_call=100\n",
    "max_results = 500\n",
    "\n",
    "print(\"The intra-day hour interval is set to\", interval, \"Edit the code if desired to change this\")\n",
    "print(\"The number of tweets per interval is set to\", max_results, \"Edit the code if desired to change this\")\n",
    "print(\"please input two dates in the format below to collect dates\\n\\t\", example_start_date, example_end_date, \"\\n\")\n",
    "user_dates = input(\"\\t\")\n",
    "print()\n",
    "start_date, end_date = user_dates.split(' ')\n",
    "test_dates = days_to_collect(start_date, end_date, str(interval))\n",
    "\n",
    "if (datetime.datetime.fromtimestamp(time.time()) - datetime.datetime.strptime(start_date, '%Y-%m-%d')).days < 30:\n",
    "    premium_search_args = premium_search_args_30day\n",
    "    print(\"will use 30-day dev environment\")\n",
    "else:\n",
    "    premium_search_args = premium_search_args_fullarchive\n",
    "    print(\"will use full-archive dev environment\")\n",
    "    \n",
    "print(\"\\ntwitter recognized dates will be collected on the closed iterval from\", start_date, \"to\", end_date, \"spaced in\", str(interval), \"hour intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810010000\", \"fromDate\": \"201809301200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810011200\", \"fromDate\": \"201810010000\"}\n",
      "waiting 2 seconds\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810020000\", \"fromDate\": \"201810011200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810021200\", \"fromDate\": \"201810020000\"}\n",
      "waiting 60 seconds\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810030000\", \"fromDate\": \"201810021200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810031200\", \"fromDate\": \"201810030000\"}\n",
      "waiting 2 seconds\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810040000\", \"fromDate\": \"201810031200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810041200\", \"fromDate\": \"201810040000\"}\n",
      "waiting 60 seconds\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810050000\", \"fromDate\": \"201810041200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810051200\", \"fromDate\": \"201810050000\"}\n",
      "waiting 2 seconds\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in range(0,len(test_dates[:-1])):\n",
    "    tweets = np.append(tweets, collect_tweets(test_dates[i], test_dates[i+1], max_results=max_results))\n",
    "    \n",
    "    # Requests are limited to 30 per minute for sandbox, 60 for subscriptions \n",
    "    # Requests are limited to 10 per second\n",
    "    num_calls = (i + 1) * max_results//results_per_call\n",
    "    if num_calls % 10 == 0 and num_calls % 20 != 0:\n",
    "        print(\"waiting 2 seconds\")\n",
    "        time.sleep(2)\n",
    "    if num_calls % 20 == 0:\n",
    "        print(\"waiting 60 seconds\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Fri Oct 05 11:48:36 +0000 2018',\n",
       " 'id': 1048178138142765057,\n",
       " 'id_str': '1048178138142765057',\n",
       " 'text': \"Bitcoin Won't Break $9,000 This Year, Galaxy Digitalâ€™s Novogratz Says https://t.co/ZqBCklNFBY https://t.co/2NdQZIJTpR\",\n",
       " 'display_text_range': [0, 93],\n",
       " 'source': '<a href=\"https://dlvrit.com/\" rel=\"nofollow\">dlvr.it</a>',\n",
       " 'truncated': False,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'user': {'id': 25382122,\n",
       "  'id_str': '25382122',\n",
       "  'name': 'startupcrunch',\n",
       "  'screen_name': 'startupcrunch',\n",
       "  'location': 'Palo Alto, CA',\n",
       "  'url': 'https://twitter.com/startupcrunch',\n",
       "  'description': 'startups, angels, venture capital. Fresh 24 hours a day.',\n",
       "  'translator_type': 'none',\n",
       "  'protected': False,\n",
       "  'verified': False,\n",
       "  'followers_count': 17321,\n",
       "  'friends_count': 3631,\n",
       "  'listed_count': 2253,\n",
       "  'favourites_count': 11,\n",
       "  'statuses_count': 1811670,\n",
       "  'created_at': 'Thu Mar 19 20:49:05 +0000 2009',\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': True,\n",
       "  'lang': 'en',\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'profile_background_color': '9AE4E8',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_link_color': '0084B4',\n",
       "  'profile_sidebar_border_color': 'FFFFFF',\n",
       "  'profile_sidebar_fill_color': 'DDFFCC',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/458747202068705280/HEuCuvpT_normal.png',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/458747202068705280/HEuCuvpT_normal.png',\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/25382122/1398273731',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': None,\n",
       "  'follow_request_sent': None,\n",
       "  'notifications': None},\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'quote_count': 0,\n",
       " 'reply_count': 0,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'entities': {'hashtags': [],\n",
       "  'urls': [{'url': 'https://t.co/ZqBCklNFBY',\n",
       "    'expanded_url': 'http://dlvr.it/QmNly3',\n",
       "    'display_url': 'dlvr.it/QmNly3',\n",
       "    'indices': [70, 93]}],\n",
       "  'user_mentions': [],\n",
       "  'symbols': [],\n",
       "  'media': [{'id': 1048178136230256640,\n",
       "    'id_str': '1048178136230256640',\n",
       "    'indices': [94, 117],\n",
       "    'media_url': 'http://pbs.twimg.com/media/Dovgdh9V4AA4XwI.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/Dovgdh9V4AA4XwI.jpg',\n",
       "    'url': 'https://t.co/2NdQZIJTpR',\n",
       "    'display_url': 'pic.twitter.com/2NdQZIJTpR',\n",
       "    'expanded_url': 'https://twitter.com/startupcrunch/status/1048178138142765057/photo/1',\n",
       "    'type': 'photo',\n",
       "    'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'large': {'w': 740, 'h': 493, 'resize': 'fit'},\n",
       "     'small': {'w': 680, 'h': 453, 'resize': 'fit'},\n",
       "     'medium': {'w': 740, 'h': 493, 'resize': 'fit'}}}]},\n",
       " 'extended_entities': {'media': [{'id': 1048178136230256640,\n",
       "    'id_str': '1048178136230256640',\n",
       "    'indices': [94, 117],\n",
       "    'media_url': 'http://pbs.twimg.com/media/Dovgdh9V4AA4XwI.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/Dovgdh9V4AA4XwI.jpg',\n",
       "    'url': 'https://t.co/2NdQZIJTpR',\n",
       "    'display_url': 'pic.twitter.com/2NdQZIJTpR',\n",
       "    'expanded_url': 'https://twitter.com/startupcrunch/status/1048178138142765057/photo/1',\n",
       "    'type': 'photo',\n",
       "    'sizes': {'thumb': {'w': 150, 'h': 150, 'resize': 'crop'},\n",
       "     'large': {'w': 740, 'h': 493, 'resize': 'fit'},\n",
       "     'small': {'w': 680, 'h': 453, 'resize': 'fit'},\n",
       "     'medium': {'w': 740, 'h': 493, 'resize': 'fit'}}}]},\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'possibly_sensitive': False,\n",
       " 'filter_level': 'low',\n",
       " 'lang': 'en',\n",
       " 'matching_rules': [{'tag': None}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To dataframe and csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def to_df(tweets):\n",
    "    # create a pandas df from tweets\n",
    "    S2 = pd.DataFrame(columns=['tweets', 'date', 'user_name', 'user_screen_name', 'user_followers', \n",
    "                           'user_friends', 'user_verified', 'user_language', 'retweet_count', 'favorite_count'])\n",
    "\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        S2.loc[i] = [tweet['text'], \n",
    "                     tweet['created_at'], \n",
    "                     tweet['user']['name'], \n",
    "                     tweet['user']['screen_name'], \n",
    "                     tweet['user']['followers_count'], \n",
    "                     tweet['user']['friends_count'], \n",
    "                     tweet['user']['verified'], \n",
    "                     tweet['user']['lang'], \n",
    "                     tweet['retweet_count'], \n",
    "                     tweet['favorite_count']] \n",
    "    return S2\n",
    "\n",
    "S2 = to_df(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_language</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Bitcoin Fails to Record a Big Surge But Market...</td>\n",
       "      <td>Fri Oct 05 11:48:39 +0000 2018</td>\n",
       "      <td>TradingBTC</td>\n",
       "      <td>tradingbtc1</td>\n",
       "      <td>3702</td>\n",
       "      <td>3094</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>#ICO   This project firts of all contains a lo...</td>\n",
       "      <td>Fri Oct 05 11:48:38 +0000 2018</td>\n",
       "      <td>Nura Alam</td>\n",
       "      <td>nuraalam324</td>\n",
       "      <td>3330</td>\n",
       "      <td>2889</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Tether Collapse Could Bring Bitcoin Black Frid...</td>\n",
       "      <td>Fri Oct 05 11:48:37 +0000 2018</td>\n",
       "      <td>startupcrunch</td>\n",
       "      <td>startupcrunch</td>\n",
       "      <td>17321</td>\n",
       "      <td>3631</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Long/Short Bitcoin moves with up to 100x Lever...</td>\n",
       "      <td>Fri Oct 05 11:48:37 +0000 2018</td>\n",
       "      <td>kerrygonxo</td>\n",
       "      <td>kerrygonxo</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Bitcoin Won't Break $9,000 This Year, Galaxy D...</td>\n",
       "      <td>Fri Oct 05 11:48:36 +0000 2018</td>\n",
       "      <td>startupcrunch</td>\n",
       "      <td>startupcrunch</td>\n",
       "      <td>17321</td>\n",
       "      <td>3631</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  \\\n",
       "4995  Bitcoin Fails to Record a Big Surge But Market...   \n",
       "4996  #ICO   This project firts of all contains a lo...   \n",
       "4997  Tether Collapse Could Bring Bitcoin Black Frid...   \n",
       "4998  Long/Short Bitcoin moves with up to 100x Lever...   \n",
       "4999  Bitcoin Won't Break $9,000 This Year, Galaxy D...   \n",
       "\n",
       "                                date      user_name user_screen_name  \\\n",
       "4995  Fri Oct 05 11:48:39 +0000 2018     TradingBTC      tradingbtc1   \n",
       "4996  Fri Oct 05 11:48:38 +0000 2018      Nura Alam      nuraalam324   \n",
       "4997  Fri Oct 05 11:48:37 +0000 2018  startupcrunch    startupcrunch   \n",
       "4998  Fri Oct 05 11:48:37 +0000 2018     kerrygonxo       kerrygonxo   \n",
       "4999  Fri Oct 05 11:48:36 +0000 2018  startupcrunch    startupcrunch   \n",
       "\n",
       "     user_followers user_friends user_verified user_language retweet_count  \\\n",
       "4995           3702         3094         False            en             0   \n",
       "4996           3330         2889         False            en             0   \n",
       "4997          17321         3631         False            en             0   \n",
       "4998             51            0         False            en             0   \n",
       "4999          17321         3631         False            en             0   \n",
       "\n",
       "     favorite_count  \n",
       "4995              0  \n",
       "4996              1  \n",
       "4997              0  \n",
       "4998              0  \n",
       "4999              0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved files complete_tweets/tweets_2018-12-01_2018-12-15_Tweets.csv and complete_tweets/tweets_2018-12-01_2018-12-15_Metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# save file to csv\n",
    "S2_tweets = S2.loc[:,['tweets']]\n",
    "S2_meta = S2.drop(['tweets'], axis=1)\n",
    "\n",
    "filename = 'complete_tweets/tweets_' + start_date + '_' + end_date\n",
    "S2_tweets.to_csv(filename + '_Tweets.csv', index=False)\n",
    "S2_meta.to_csv(filename + '_Metadata.csv', index=False)\n",
    "print('saved files', filename + '_Tweets.csv', 'and', filename + '_Metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
