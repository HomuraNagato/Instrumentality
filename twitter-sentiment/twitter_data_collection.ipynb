{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter data collection\n",
    "\n",
    "#### References\n",
    "\n",
    "searchtweets API reference: https://twitterdev.github.io/search-tweets-python/  \n",
    "Twitter API reference: https://developer.twitter.com/en/docs/tweets/search/api-reference/premium-search.html  \n",
    "Twitter tweet object and dictionary: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grabbing bearer token from OAUTH\n",
      "Grabbing bearer token from OAUTH\n"
     ]
    }
   ],
   "source": [
    "from searchtweets import ResultStream, gen_rule_payload, load_credentials, collect_results\n",
    "\n",
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# plotting and visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "premium_search_args_30day = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_30day\",\n",
    "                                          env_overwrite=False)\n",
    "premium_search_args_fullarchive = load_credentials(\"~/.twitter_keys.yaml\",\n",
    "                                          yaml_key=\"search_tweets_premium_fullarchive\",\n",
    "                                          env_overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_to_collect(start, end, frequency):\n",
    "    '''\n",
    "    will return an array starting at midnight of desired date to last frequency hour of end date\n",
    "    start = start date\n",
    "    end = end date\n",
    "    frequency = number of hours to step by per day. For example frequency = 12, will collect twice: at midnight and noon\n",
    "    '''\n",
    "    # add one day for right_side border case\n",
    "    # pd.date_range only allows dates, use rounding dates and closed='right' to get desired dates\n",
    "    #print(start, end)\n",
    "    start = datetime.datetime.strptime(start, '%Y-%m-%d') - datetime.timedelta(days=0, hours=int(frequency))\n",
    "    end = datetime.datetime.strptime(end, '%Y-%m-%d') + datetime.timedelta(days=1, hours=0)\n",
    "    #print(start, end)\n",
    "    dates = pd.date_range(start=start, end=end, freq=frequency+'H', closed='left')\n",
    "    formatted_dates = [ datetime.datetime.strftime(t, '%Y%m%d%H%M') for t in dates ]\n",
    "    #print(formatted_dates)\n",
    "    return formatted_dates\n",
    "\n",
    "def collect_tweets(from_date, to_date, max_results):\n",
    "    # maxResults is capped at 100 for sandbox account, even though there should be a next function to get more, it \n",
    "    # appears max_results=500 is accepted without any extra work\n",
    "    # date format: YYYY-mm-DD HH:MM\n",
    "    # from_date is inclusive. to_date is non-inclusive. Appears to start at from_date and start collecting tweets working\n",
    "    # backwards to to_date\n",
    "    bitcoin_rule = gen_rule_payload(\"bitcoin\", results_per_call=100, from_date=from_date, to_date=to_date) \n",
    "    print(bitcoin_rule)\n",
    "    collected_tweets = collect_results(bitcoin_rule, max_results=max_results, result_stream_args=premium_search_args)\n",
    "    return collected_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intra-day hour interval is set to 12 Edit the code if desired to change this\n",
      "The number of tweets per interval is set to 500 Edit the code if desired to change this\n",
      "please input two dates in the format below to collect dates\n",
      "\t 2018-10-11 2018-10-15 \n",
      "\n",
      "\t2018-10-11 2018-10-15\n",
      "\n",
      "will use full-archive dev environment\n",
      "\n",
      "twitter recognized dates will be collected on the closed iterval from 2018-10-11 to 2018-10-15 spaced in 12 hour intervals\n"
     ]
    }
   ],
   "source": [
    "example_start_date = '2018-10-11'\n",
    "example_end_date = '2018-10-15'\n",
    "interval = 12\n",
    "results_per_call=100\n",
    "max_results = 500\n",
    "\n",
    "print(\"The intra-day hour interval is set to\", interval, \"Edit the code if desired to change this\")\n",
    "print(\"The number of tweets per interval is set to\", max_results, \"Edit the code if desired to change this\")\n",
    "print(\"please input two dates in the format below to collect dates\\n\\t\", example_start_date, example_end_date, \"\\n\")\n",
    "user_dates = input(\"\\t\")\n",
    "print()\n",
    "start_date, end_date = user_dates.split(' ')\n",
    "test_dates = days_to_collect(start_date, end_date, str(interval))\n",
    "\n",
    "if (datetime.datetime.fromtimestamp(time.time()) - datetime.datetime.strptime(start_date, '%Y-%m-%d')).days < 15:\n",
    "    premium_search_args = premium_search_args_30day\n",
    "    print(\"will use 30-day dev environment\")\n",
    "else:\n",
    "    premium_search_args = premium_search_args_fullarchive\n",
    "    print(\"will use full-archive dev environment\")\n",
    "    \n",
    "print(\"\\ntwitter recognized dates will be collected on the closed iterval from\", start_date, \"to\", end_date, \"spaced in\", str(interval), \"hour intervals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810140000\", \"fromDate\": \"201810131200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810141200\", \"fromDate\": \"201810140000\"}\n",
      "waiting 2 seconds\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810150000\", \"fromDate\": \"201810141200\"}\n",
      "{\"query\": \"bitcoin\", \"maxResults\": 100, \"toDate\": \"201810151200\", \"fromDate\": \"201810150000\"}\n",
      "waiting 2 seconds\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "for i in range(0,len(test_dates[:-1])):\n",
    "    tweets = np.append(tweets, collect_tweets(test_dates[i], test_dates[i+1], max_results=max_results))\n",
    "    \n",
    "    # Requests are limited to 30 per second for sandbox, 60 for subscriptions \n",
    "    # Requests are limited to 10 per second\n",
    "    num_calls = (i + 1) * max_results//results_per_call\n",
    "    if num_calls % 10 == 0:\n",
    "        print(\"waiting 2 seconds\")\n",
    "        time.sleep(2)\n",
    "    if num_calls % 60 == 0:\n",
    "        print(\"waiting 60 seconds\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To dataframe and csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tweets  \\\n",
      "0  RT @ICOVOCO: We will hold meetup \"A Cypherpunk...   \n",
      "1  RT @europecoinEUORG: A KAZE SOLUTIONS and EURO...   \n",
      "2  Bitcoin, Ethereum, Ripple, Bitcoin Cash, EOS, ...   \n",
      "3  RT @Alt__Magazine: In 2017, the global blockch...   \n",
      "4  RT @Jayga322: Sooo many connections!\\n\\n#Trump...   \n",
      "\n",
      "                             date             user_name user_screen_name  \\\n",
      "0  Wed Oct 10 23:59:55 +0000 2018                 space      iimincrypto   \n",
      "1  Wed Oct 10 23:59:49 +0000 2018            JOOMLA SEO     szenekonzept   \n",
      "2  Wed Oct 10 23:59:48 +0000 2018           Crypto News    CryptoNews_io   \n",
      "3  Wed Oct 10 23:59:48 +0000 2018                  will     im_just_will   \n",
      "4  Wed Oct 10 23:59:46 +0000 2018  Jericho Jones ⭐️⭐️⭐️         Jayga322   \n",
      "\n",
      "  user_followers user_friends user_verified user_language retweet_count  \\\n",
      "0           5521         5949         False            ko             0   \n",
      "1          14206        13224         False            de             0   \n",
      "2            249           31         False            en             0   \n",
      "3             64           66         False            en             0   \n",
      "4           4359         4917         False            en             0   \n",
      "\n",
      "  favorite_count  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n"
     ]
    }
   ],
   "source": [
    "def to_df(tweets):\n",
    "    # create a pandas df from tweets\n",
    "    S2 = pd.DataFrame(columns=['tweets', 'date', 'user_name', 'user_screen_name', 'user_followers', \n",
    "                           'user_friends', 'user_verified', 'user_language', 'retweet_count', 'favorite_count'])\n",
    "\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        S2.loc[i] = [tweet['text'], \n",
    "                     tweet['created_at'], \n",
    "                     tweet['user']['name'], \n",
    "                     tweet['user']['screen_name'], \n",
    "                     tweet['user']['followers_count'], \n",
    "                     tweet['user']['friends_count'], \n",
    "                     tweet['user']['verified'], \n",
    "                     tweet['user']['lang'], \n",
    "                     tweet['retweet_count'], \n",
    "                     tweet['favorite_count']] \n",
    "    return S2\n",
    "\n",
    "S2 = to_df(tweets)\n",
    "\n",
    "print(S2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved files tweets_2018-10-11_2018-10-15_Tweets.csv and tweets_2018-10-11_2018-10-15_Metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# save file to csv\n",
    "S2_tweets = S2.loc[:,['tweets']]\n",
    "S2_meta = S2.drop(['tweets'], axis=1)\n",
    "\n",
    "filename = 'tweets_' + start_date + '_' + end_date\n",
    "S2_tweets.to_csv(filename + '_Tweets.csv', index=False)\n",
    "S2_meta.to_csv(filename + '_Metadata.csv', index=False)\n",
    "print('saved files', filename + '_Tweets.csv', 'and', filename + '_Metadata.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
